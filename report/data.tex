\subsection*{Data}
We are working with traffic news data.
More specifically, we have a set of traffic news reports that serve as a part of our training data.
The other part is hidden in the periodically scraped website data that in some way or another corresponds to parts of the traffic news reports.
The input to our NLP model will be unseen scraped website data, whereas the output will be a report that follows the intended format.


\subsubsection*{Models}
We used an open-source large language model (LLM) named GaMS-27B-Instruct\footnote{https://huggingface.co/cjvt/GaMS-27B-Instruct} to generate new data.
Since our data is basically completely in Slovenian, we needed an LLM that was trained specifically in this language.
Technically speaking, it is a fine-tuned version of the Google Gemma2 LLM\footnote{https://huggingface.co/google/gemma-2-27b}, so it performs well both on English and Slovenian.

\subsubsection*{Data preprocessing variants}
We chose two implement two different preprocessing pipelines:
\begin{itemize}
    \item - Data preprocessing 1 (DP1), which creates input-output pairs of reports by taking an output (given a date) and pairing it with a flattened-input using multiple temporally-close inputs
    \item - Data preprocessing 2 (DP2), which splits the reports into paragraphs and tries to make input-output pairs using various NLP techniques for matching.
\end{itemize}

Both of these aim to take the given data and convert it into a specific format: a list of input-output pairs that we would like the LLM to ``learn from''.

\subsubsection*{Preprocessing Pipeline (DP1)}

To align structured traffic logs from \texttt{promet.si} with RTV Slovenija's RTF reports, we designed a multi-step preprocessing pipeline:

\paragraph{1. Temporal Filtering.}
We extract all structured events within a 1–8 hour window prior to the RTF timestamp, ensuring coverage of both new and persistent incidents.

\paragraph{2. Cleaning and Normalization.}
All fields are cleaned using HTML stripping, whitespace collapsing, and timestamp normalization to \texttt{datetime}.

\paragraph{3. Sentence Extraction and Deduplication.}
Each row is split into sentences and deduplicated using:
\begin{itemize}
  \item \textbf{Exact match:} Removes literal duplicates.
  \item \textbf{Semantic match:} Uses Sentence-BERT with cosine similarity $> 0.7$.
\end{itemize}

\paragraph{4. Content Selection.}
We retain key sentences via:
\begin{itemize}
  \item Longest informative sentence,
  \item TF-IDF scoring,
  \item Named entity filtering (e.g., roads, locations).
\end{itemize}

\paragraph{5. Input Formatting.}
Selected sentences are flattened into either:
\begin{itemize}
  \item[\textbf{(a)}] Plain concatenation (minimal preprocessing), or
  \item[\textbf{(b)}] RTV-style header with “\texttt{Prometne informacije DD.MM.YYYY HH.MM}” and “\texttt{Podatki o prometu.}” prefix.
\end{itemize}

\paragraph{6. RTF Matching.}
The closest-in-time RTF is parsed via regex to extract the reference summary.

This pipeline produces coherent model inputs structurally aligned with real RTV outputs and supports both evaluation and fine-tuning.


% \subsection*{Fine-tuning}
% In order for our data to be used in fine-tuning. we made input-output pairs from year 2022, as the procedure was long and computationally slow as well as keeping some information hidden from the model so it could be used as an evaluation set. 

\subsubsection*{Preprocessing pipeline (DP2)}
This pipeline is somewhat simpler in nature.
It takes a given output and finds its best possible corresponding input.
The stages include:
\begin{itemize}
    \item Split given report (output) into individual events.
    \item Find and split temporally-close input data (from excel).
    % \item Split input data also into events.
    \item Compare each event from the given report with all events from the input.
    \item Create input-output pairs using matches that meet a confidence threshold.
\end{itemize}

\paragraph{1. Splitting into events.}
After visually observing the dataset, we observed that the outputs (individual RTF files) are split into multiple paragraphs and that each paragraph corresponds to one event or a group of related events.
In other words, the contents of different paragraphs pertain to different news stories.
Additionally, each line in the input data (excel line) consist of multiple columns that can be (carefully) merged.
After being merged, we notice that this data can also be split into events by the html tags.
After this stage, we split every data point in the input and output into a series of events.

\paragraph{2. Finding temporally-close input data.}
This stage is fairly similar to its analogue from DP1.
We simply take all the input data from a time-window around the time that the output data was obtained and split it into a flat list of events (outputs).

\paragraph{3. Matching inputs to a given output.}
After the previous stage, we have a single output event and a list of candidate input events.
We implemented a multi-stage paragraph-comparison procedure.
This procedure takes into account the number of matching words, proper nouns (PN) and named entities (NE).
The latter two have a significant overlap since they both roughly refer to a specific person, location, object etc., but are not the same in their implementation.
We searched for pairs of matching words using Levenshtein distance on the lemmatized paragraphs (maximum distance of 1 for a match).
Any given input-output pair (of events) had to pass a series of trials, where it would need to pass an adjusted minimum threshold for the number matching words, PNs and NEs.
Finally, the pair needed to also achieve a high enough score using vector embeddings comparison.
