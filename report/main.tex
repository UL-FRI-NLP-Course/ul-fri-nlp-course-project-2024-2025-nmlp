%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FRI Data Science_report LaTeX Template
% Version 1.0 (28/1/2020)
% 
% Jure Demšar (jure.demsar@fri.uni-lj.si)
%
% Based on MicromouseSymp article template by:
% Mathias Legrand (legrand.mathias@gmail.com) 
% With extensive modifications by:
% Antonio Valente (antonio.luis.valente@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[fleqn,moreauthors,10pt]{ds_report}
\usepackage[english]{babel}
\usepackage{minted}

\setminted{
  fontsize=\small, 
  breaklines=true, 
  breakafter={.,\space}, 
  breakbytokenanywhere=true, 
  frame=single,
}

\graphicspath{{fig/}}




%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

% Header
\JournalInfo{FRI Natural language processing course 2025}

% Interim or final report
\Archive{Project report} 
%\Archive{Final report} 

% Article title
\PaperTitle{Automatic generation of Slovenian traffic news for RTV Slovenija} 

% Authors (student competitors) and their info
\Authors{Anže Hočevar in Jan Anžur}

% Advisors
\affiliation{\textit{Advisors: Slavko Žitnik}}

% Keywords
\Keywords{Large language model, fine-tuning, data processing}
\newcommand{\keywordname}{Keywords}


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{
This project investigates the automatic generation of Slovenian traffic news using large language models (LLMs), aiming to emulate the structure and content style of RTV Slovenija bulletins. We propose and compare three data preparation pipelines—basic, DP1, and DP2—which align structured traffic events from \texttt{promet.si} with reference summaries from RTF reports. The GaMS-27B-Instruct model is fine-tuned using these pipelines via instruction-tuning and LoRA adaptation. Evaluation includes lexical overlap, edit distance, and semantic similarity metrics, alongside API-based LLM scoring. Results indicate that while DP1 yields the most structurally faithful outputs, basic and DP2 variants are often preferred by LLM evaluators due to their greater flexibility. The findings suggest a trade-off between rigid formatting and content adaptability, with implications for both training strategy and prompt design in multilingual, domain-specific text generation.
}

%----------------------------------------------------------------------------------------

\begin{document}

% Makes all text pages the same height
\flushbottom 

% Print the title and abstract box
\maketitle 

% Removes page numbering from the first page
\thispagestyle{empty} 

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------


	% These latex files are intended to serve as a the template for the NLP course at FRI.  The template is adapted from the FRI Data Science Project Competition. template  If you find mistakes in the template or have problems using it, please consult Jure Demšar (\href{mailto:jure.demsar@fri.uni-lj.si}{jure.demsar@fri.uni-lj.si}).
	
	% In the Introduction section you should write about the relevance of your work (what is the purpose of the project, what will we solve) and about related work (what solutions for the problem already exist). Where appropriate, reference scientific work conducted by other researchers. For example, the work done by Demšar et al. \cite{Demsar2016BalancedMixture} is very important for our project. The abbreviation et al. is for et alia, which in latin means and others, we use this abbreviation when there are more than two authors of the work we are citing. If there are two authors (or if there is a single author) we just write down their surnames. For example, the work done by Demšar and Lebar Bajec \cite{Demsar2017LinguisticEvolution} is also important for successful completion of our project.

\input{intro}

\input{literature}



%------------------------------------------------

\section*{Methods}

\input{data}


\section*{Baseline results}

% gams-27B-Instruct

As a starting point, we attempted to approach this task by simply using just common prompt engineering methods.
To put it more bluntly, we fed the LLM with a prompt that concisely and clearly describes the task at hand and provided a sequence of shots (examples) that it should be able to follow.
An example of this approach in action is shown in figure~\ref{fig:result_baseline}.
It is apparent that the output is very similar to the input.
Although, this is not necessarily bad, as long as the rules for data generation are not violated.


\section*{Fine-Tuning: Training Data Generation and Model Adaptation}
To fine-tune our large language models (LLMs) on domain-specific Slovenian traffic news reports, we prepared a high-quality set of input–output training examples derived from publicly available sources. This pipeline is computationally intensive due to large-scale RTF parsing, semantic deduplication, and format conversion.
% As such, we preprocessed and extracted all pairs for the year 2022, leaving 2023–2024 for evaluation and held-out testing.

\paragraph{1. Input–Output Pair Generation.}
These pairs are stored in JSONL format for training with one object per line:
\{ "input": "...", "output": "..." \}.
We convert structured excel logs and corresponding RTF summaries into training examples in the format:

DP1:

VHOD:
\textless flattened, cleaned input paragraph \textgreater

IZHOD:
\textless RTF-sourced summary matching the input's timestamp context (ground truth) \textgreater
\\

DP2:

VHOD:
\textless the input part of a match \textgreater

IZHOD:
\textless the output part of the match \textgreater

\paragraph{2. Prompt Construction.}
We then formatted these pairs into an instruction-tuning template. It includes:

A task description (e.g. “You are a traffic report writer...”),

Three few-shot examples,

The current input as the final prompt, expecting model completion.

The style would be similar to what the LLM would recieve as input for inference after being fine-tuned.

\subsection*{3. Training Setup.}
Models such as GaMS-2B, GaMS-9B-Instruct and GaMS-27B are fine-tuned using PEFT (LoRA) on each of the data preparation techniques, leveraging Hugging Face pipelines and mixed-precision execution. Inference outputs are saved in outputs.jsonl for evaluation. 

\textbf{LoRA Configuration.} The model was fine-tuned using Low-Rank Adaptation (LoRA) with the following parameters:

\begin{itemize}
  \item \textbf{\texttt{task\_type} = \texttt{CAUSAL\_LM}} — Targets causal language modeling tasks.
  \item \textbf{\texttt{r} = 64} — Rank of the low-rank adapter matrices.
  \item \textbf{\texttt{lora\_alpha} = 64} — Scaling factor applied to the adapter outputs.
  \item \textbf{\texttt{lora\_dropout} = 0.1} — Dropout probability applied to adapter layers.
  \item \textbf{\texttt{bias} = \texttt{"none"}} — Bias terms are not adapted.
\end{itemize}

\input{results}



% Use the Methods section to describe what you did an how you did it -- in what way did you prepare the data, what algorithms did you use, how did you test various solutions ... Provide all the required details for a reproduction of your work.

% Below are \LaTeX examples of some common elements that you will probably need when writing your report (e.g. figures, equations, lists, code examples ...).


% \subsection*{Equations}

% You can write equations inline, e.g. $\cos\pi=-1$, $E = m \cdot c^2$ and $\alpha$, or you can include them as separate objects. The Bayes’s rule is stated mathematically as:

% \begin{equation}
% 	P(A|B) = \frac{P(B|A)P(A)}{P(B)},
% 	\label{eq:bayes}
% \end{equation}

% where $A$ and $B$ are some events. You can also reference it -- the equation \ref{eq:bayes} describes the Bayes's rule.

% \subsection*{Lists}

% We can insert numbered and bullet lists:

% % the [noitemsep] option makes the list more compact
% \begin{enumerate}[noitemsep] 
% 	\item First item in the list.
% 	\item Second item in the list.
% 	\item Third item in the list.
% \end{enumerate}

% \begin{itemize}[noitemsep] 
% 	\item First item in the list.
% 	\item Second item in the list.
% 	\item Third item in the list.
% \end{itemize}

% We can use the description environment to define or describe key terms and phrases.

% \begin{description}
% 	\item[Word] What is a word?.
% 	\item[Concept] What is a concept?
% 	\item[Idea] What is an idea?
% \end{description}


% \subsection*{Random text}

% This text is inserted only to make this template look more like a proper report. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam blandit dictum facilisis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Etiam convallis tellus velit, quis ornare ipsum aliquam id. Maecenas tempus mauris sit amet libero elementum eleifend. Nulla nunc orci, consectetur non consequat ac, consequat non nisl. Aenean vitae dui nec ex fringilla malesuada. Proin elit libero, faucibus eget neque quis, condimentum laoreet urna. Etiam at nunc quis felis pulvinar dignissim. Phasellus turpis turpis, vestibulum eget imperdiet in, molestie eget neque. Curabitur quis ante sed nunc varius dictum non quis nisl. Donec nec lobortis velit. Ut cursus, libero efficitur dictum imperdiet, odio mi fermentum dui, id vulputate metus velit sit amet risus. Nulla vel volutpat elit. Mauris ex erat, pulvinar ac accumsan sit amet, ultrices sit amet turpis.

% Phasellus in ligula nunc. Vivamus sem lorem, malesuada sed pretium quis, varius convallis lectus. Quisque in risus nec lectus lobortis gravida non a sem. Quisque et vestibulum sem, vel mollis dolor. Nullam ante ex, scelerisque ac efficitur vel, rhoncus quis lectus. Pellentesque scelerisque efficitur purus in faucibus. Maecenas vestibulum vulputate nisl sed vestibulum. Nullam varius turpis in hendrerit posuere.


% \subsection*{Figures}

% You can insert figures that span over the whole page, or over just a single column. The first one, \figurename~\ref{fig:column}, is an example of a figure that spans only across one of the two columns in the report.

% \begin{figure}[ht]\centering
% 	\includegraphics[width=\linewidth]{single_column.pdf}
% 	\caption{\textbf{A random visualization.} This is an example of a figure that spans only across one of the two columns.}
% 	\label{fig:column}
% \end{figure}

% On the other hand, \figurename~\ref{fig:whole} is an example of a figure that spans across the whole page (across both columns) of the report.

% % \begin{figure*} makes the figure take up the entire width of the page
% \begin{figure*}[ht]\centering 
% 	\includegraphics[width=\linewidth]{whole_page.pdf}
% 	\caption{\textbf{Visualization of a Bayesian hierarchical model.} This is an example of a figure that spans the whole width of the report.}
% 	\label{fig:whole}
% \end{figure*}


% \subsection*{Tables}

% Use the table environment to insert tables.

% \begin{table}[hbt]
% 	\caption{Table of grades.}
% 	\centering
% 	\begin{tabular}{l l | r}
% 		\toprule
% 		\multicolumn{2}{c}{Name} \\
% 		\cmidrule(r){1-2}
% 		First name & Last Name & Grade \\
% 		\midrule
% 		John & Doe & $7.5$ \\
% 		Jane & Doe & $10$ \\
% 		Mike & Smith & $8$ \\
% 		\bottomrule
% 	\end{tabular}
% 	\label{tab:label}
% \end{table}


% \subsection*{Code examples}

% You can also insert short code examples. You can specify them manually, or insert a whole file with code. Please avoid inserting long code snippets, advisors will have access to your repositories and can take a look at your code there. If necessary, you can use this technique to insert code (or pseudo code) of short algorithms that are crucial for the understanding of the manuscript.

% \lstset{language=Python}
% \lstset{caption={Insert code directly from a file.}}
% \lstset{label={lst:code_file}}
% \lstinputlisting[language=Python]{code/example.py}

% \lstset{language=R}
% \lstset{caption={Write the code you want to insert.}}
% \lstset{label={lst:code_direct}}
% \begin{lstlisting}
% import(dplyr)
% import(ggplot)

% ggplot(diamonds,
% 	   aes(x=carat, y=price, color=cut)) +
%   geom_point() +
%   geom_smooth()
% \end{lstlisting}


% Use the results section to present the final results of your work. Present the results in a objective and scientific fashion. Use visualisations to convey your results in a clear and efficient manner. When comparing results between various techniques use appropriate statistical methodology.

% \subsection*{More random text}

% This text is inserted only to make this template look more like a proper report. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam blandit dictum facilisis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Etiam convallis tellus velit, quis ornare ipsum aliquam id. Maecenas tempus mauris sit amet libero elementum eleifend. Nulla nunc orci, consectetur non consequat ac, consequat non nisl. Aenean vitae dui nec ex fringilla malesuada. Proin elit libero, faucibus eget neque quis, condimentum laoreet urna. Etiam at nunc quis felis pulvinar dignissim. Phasellus turpis turpis, vestibulum eget imperdiet in, molestie eget neque. Curabitur quis ante sed nunc varius dictum non quis nisl. Donec nec lobortis velit. Ut cursus, libero efficitur dictum imperdiet, odio mi fermentum dui, id vulputate metus velit sit amet risus. Nulla vel volutpat elit. Mauris ex erat, pulvinar ac accumsan sit amet, ultrices sit amet turpis.

% Phasellus in ligula nunc. Vivamus sem lorem, malesuada sed pretium quis, varius convallis lectus. Quisque in risus nec lectus lobortis gravida non a sem. Quisque et vestibulum sem, vel mollis dolor. Nullam ante ex, scelerisque ac efficitur vel, rhoncus quis lectus. Pellentesque scelerisque efficitur purus in faucibus. Maecenas vestibulum vulputate nisl sed vestibulum. Nullam varius turpis in hendrerit posuere.

% Nulla rhoncus tortor eget ipsum commodo lacinia sit amet eu urna. Cras maximus leo mauris, ac congue eros sollicitudin ac. Integer vel erat varius, scelerisque orci eu, tristique purus. Proin id leo quis ante pharetra suscipit et non magna. Morbi in volutpat erat. Vivamus sit amet libero eu lacus pulvinar pharetra sed at felis. Vivamus non nibh a orci viverra rhoncus sit amet ullamcorper sem. Ut nec tempor dui. Aliquam convallis vitae nisi ac volutpat. Nam accumsan, erat eget faucibus commodo, ligula dui cursus nisi, at laoreet odio augue id eros. Curabitur quis tellus eget nunc ornare auctor.


%------------------------------------------------

\section*{Discussion}

\subsection*{Qualitative Analysis of Preparation Strategies}
To better understand how data preparation impacts generation quality, we compared representative outputs from all three variants. DP1 yielded bulletins with high structural fidelity, closely mimicking RTV Slovenija formatting (e.g., \textit{road}~$\rightarrow$~\textit{direction}~$\rightarrow$~\textit{event}~$\rightarrow$~\textit{consequence}). However, its rigid template often caused repetitive phrasing and excluded minor events outside the 8-hour window.

DP2 outputs, while lacking formal headers, showed more fluent and human-like summaries, often merging adjacent incidents effectively. These captured contextual nuance better, especially when events spanned multiple RTF paragraphs.

The basic variant produced mixed results: broader inclusion improved recall but occasionally introduced outdated or misaligned events due to the absence of temporal filtering.

Overall, LLM-based evaluations (e.g., DeepSeek V3) favored DP2 and basic over DP1, highlighting a trade-off between structural alignment (DP1) and natural summarization (DP2/basic). Future strategies may benefit from blending structural templates with adaptive, entity-aware inputs.

% 

\subsection*{Future Work}

Future improvements could include integrating \emph{named-entity alignment metrics} to better assess factual consistency (e.g., road names, locations). Adding \emph{BERTScore} or other semantic-aware metrics would complement lexical evaluations.

On the data side, \emph{adaptive temporal filtering} and hybrid strategies that combine DP1's structure with DP2's flexibility could improve both coverage and style.

Model-wise, exploring \emph{constrained decoding} or \emph{reinforcement tuning} (e.g., RLHF) may help enforce formatting and factual accuracy. Finally, incorporating \emph{external data sources} such as weather or live traffic sensors could enable real-time applications.




%------------------------------------------------

% \section*{Acknowledgments}

% Here you can thank other persons (advisors, colleagues ...) that contributed to the successful completion of your project.


%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\bibliographystyle{unsrt}
\bibliography{report}

\clearpage
\input{baseline}
\input{basic_output}
\input{dp1_output}
\input{dp2_output}
\input{chatGPT_eval}

\end{document}